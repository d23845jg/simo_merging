{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-Input Multi-Output Merging\n",
    "\n",
    "This notebook explores SIMO merging techniques for MTL with DINOv2 models. It includes model merging, LoRA adaptation, and training for tasks like segmentation, depth estimation, and surface normal prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "import wandb\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "# Local imports\n",
    "from model_merging.aggregator import aggregate_task_vectors\n",
    "from model_merging.adamerging_utils import del_attr, set_attr, load_weights\n",
    "from model_merging.eval_utils import perform_eval_with_merged_vector\n",
    "from model_merging.task_vectors import MTLTaskVector\n",
    "from model_merging.utils import compute_cosine_similarity_matrix\n",
    "from models.dinov2.mtl.multitasker import MTLDinoV2\n",
    "from training.create_network import *\n",
    "from training.utils import TaskMetric, eval\n",
    "from utils import get_data_loaders, initialize_wandb, torch_load, torch_save\n",
    "\n",
    "# Login to wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Loading the experiment configuration from a Jinja2 template file. This includes hyperparameters for training, model merging settings, and dataset configurations. The configuration is rendered and parsed as YAML for easy access throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from Jinja2 template\n",
    "env = Environment(loader=FileSystemLoader(\".\"))\n",
    "template = env.get_template(\"config/mtl.yaml.j2\")\n",
    "rendered_yaml = template.render()\n",
    "mm_config = yaml.safe_load(rendered_yaml)\n",
    "\n",
    "# Define model classes for different architectures\n",
    "model_classes = {\n",
    "    \"dinov2\": MTLDinoV2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Weights & Biases for experiment tracking\n",
    "initialize_wandb(\n",
    "    project=mm_config[\"wandb\"][\"project\"],\n",
    "    group=f\"{mm_config['training_params']['network']}\",\n",
    "    job_type=\"representation_surgery\",\n",
    "    mode=\"offline\",\n",
    "    config={\n",
    "        \"network\": mm_config[\"model_merging\"][\"network\"],\n",
    "        \"dataset\": mm_config[\"model_merging\"][\"dataset\"],\n",
    "        \"batch_size\": mm_config[\"training_params\"][\"batch_size\"],\n",
    "        \"ft_model_files\": mm_config[\"model_merging\"][\"ft_model_files\"],\n",
    "        \"method\": mm_config[\"model_merging\"][\"method\"],\n",
    "        \"seed\": mm_config[\"training_params\"][\"seed\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(mm_config[\"training_params\"][\"seed\"])\n",
    "np.random.seed(mm_config[\"training_params\"][\"seed\"])\n",
    "random.seed(mm_config[\"training_params\"][\"seed\"])\n",
    "\n",
    "# Set device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "\n",
    "Defining the multi-task learning tasks for NYUv2 and initializing the pre-trained DINOv2 model with task-specific decoder heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tasks = {\n",
    "    \"seg\": {\n",
    "        \"num_classes\": 13,\n",
    "    },\n",
    "    \"depth\": {\n",
    "        \"num_classes\": 1,\n",
    "        \"min_depth\": 0.00,\n",
    "        \"max_depth\": 10.0,\n",
    "    },\n",
    "    \"normal\": {\n",
    "        \"num_classes\": 3,\n",
    "    },\n",
    "}\n",
    "\n",
    "pt_model = MTLDinoV2(\n",
    "    arch_name=\"vit_base\",\n",
    "    head_tasks=train_tasks,  # Task configurations\n",
    "    head_archs=\"dpt-add_small\",  # Decoder architecture for heads\n",
    "    out_index=[2, 5, 8, 11],  # Output indices from transformer layers\n",
    "    cls_token=True,  # Include class token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Vectors\n",
    "\n",
    "Load fine-tuned models and compute task vectors for each task combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fine-tuned models and compute task vectors\n",
    "ts_models, task_vectors = {}, {}\n",
    "for ft_file in mm_config[\"model_merging\"][\"ft_model_files\"]:\n",
    "    ts_model = torch_load(ft_file)\n",
    "    task_vector = MTLTaskVector(pt_model, ts_model)\n",
    "\n",
    "    key = \" + \".join(task_vector.head_tasks.keys())\n",
    "    ts_models[key] = ts_model\n",
    "    task_vectors[key] = task_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and display task vector norms\n",
    "[task.title() + f\": {task_vectors[task].norm().item():.2f} \" for task in task_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity matrix between task vectors\n",
    "compute_cosine_similarity_matrix(task_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Input Multi-Output Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Preparation\n",
    "\n",
    "Preparing the model for parameter merging by making backbone parameters functional and organizing parameter lists. This includes separating pre-trained backbone parameters from task-specific adaptations for efficient merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach task-specific heads to the pre-trained model\n",
    "for task in task_vectors:\n",
    "    pt_model.load_state_dict(task_vectors[task].tau, strict=False)\n",
    "\n",
    "for head in pt_model.decoders:\n",
    "    pt_model.decoders[head].eval()\n",
    "\n",
    "pt_model_dict = pt_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make backbone parameters functional by deleting attributes\n",
    "names = list(next(iter(task_vectors.values())).theta.keys())\n",
    "for name in names:\n",
    "    del_attr(pt_model, name.split(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare parameter lists for merging: backbone and task vectors\n",
    "paramslist = []\n",
    "paramslist += [\n",
    "    tuple(\n",
    "        v.detach().requires_grad_().cpu()\n",
    "        for k, v in pt_model_dict.items()\n",
    "        if not any(task in k for task in pt_model.head_tasks)\n",
    "    )\n",
    "]  # Pretrained backbone\n",
    "paramslist += [\n",
    "    tuple(v.detach().requires_grad_().cpu() for v in tv.theta.values())\n",
    "    for tv in task_vectors.values()\n",
    "]  # Task vectors theta (backbone)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA Adaptation\n",
    "\n",
    "Defining and applying Low-Rank Adaptation to the model backbone blocks for (efficient) fine-tuning of shared representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LoRA adaptor for efficient fine-tuning\n",
    "class LoRAAdaptor(nn.Module):\n",
    "    def __init__(self, input_dim, rank):\n",
    "        super(LoRAAdaptor, self).__init__()\n",
    "        self.down_proj = nn.Linear(input_dim, rank, bias=False)\n",
    "        self.up_proj = nn.Linear(rank, input_dim, bias=False)\n",
    "        self.non_linear_func = nn.ReLU()\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.down_proj.weight, a=math.sqrt(5))\n",
    "        nn.init.zeros_(self.up_proj.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.up_proj(self.non_linear_func(self.down_proj(x)))\n",
    "\n",
    "\n",
    "def modify_block_with_lora(block, rank=16):\n",
    "    # Modify a transformer block by adding LoRA adaptation.\n",
    "    block.lora = LoRAAdaptor(block.norm2.normalized_shape[0], rank=rank)\n",
    "    original_forward = block.forward\n",
    "\n",
    "    def new_forward(x):\n",
    "        x = original_forward(x)\n",
    "        return x - block.lora(x)  # Apply LoRA adaptation\n",
    "\n",
    "    block.forward = new_forward\n",
    "\n",
    "\n",
    "def modify_decoder_with_lora(model, task, rank=16):\n",
    "    # Modify a decoder head by adding LoRA.\n",
    "    decoder = model.decoders[task]\n",
    "    decoder.lora = LoRAAdaptor(model.backbone.embed_dim, rank=rank)\n",
    "    original_forward = decoder.forward\n",
    "\n",
    "    def new_forward(x):\n",
    "        x = original_forward(x)\n",
    "        return x - decoder.lora(x)  # Apply LoRA adaptation\n",
    "\n",
    "    decoder.forward = new_forward\n",
    "\n",
    "\n",
    "def add_lora_to_model_blocks(model, rank=16):\n",
    "    for block in model.backbone.blocks:\n",
    "        modify_block_with_lora(block, rank=rank)\n",
    "\n",
    "\n",
    "def add_lora_to_model_decoders(model, rank=16):\n",
    "    for task in model.decoders:\n",
    "        modify_decoder_with_lora(model, task, rank=rank)\n",
    "\n",
    "\n",
    "add_lora_to_model_blocks(pt_model, rank=16)\n",
    "# add_lora_to_model_decoders(pt_model, rank=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Framework\n",
    "\n",
    "Defining the LambdaWrapper class that handles parameter merging with learnable merging coefficients (similar to AdaMerging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LambdaWrapper for merging parameters with learnable lambdas\n",
    "class LambdaWrapper(torch.nn.Module):\n",
    "    def __init__(self, mtl_model, paramslist, names, use_learnable_lambdas=0.0):\n",
    "        super(LambdaWrapper, self).__init__()\n",
    "        self.paramslist = paramslist\n",
    "        self.mtl_model = mtl_model\n",
    "        self.head_tasks = mtl_model.head_tasks\n",
    "        self.names = names\n",
    "        self.use_learnable_lambdas = use_learnable_lambdas\n",
    "\n",
    "        # task-wise lambdas\n",
    "        if isinstance(use_learnable_lambdas, list):\n",
    "            self.lambdas_raw = torch.Tensor(use_learnable_lambdas)  # fixed\n",
    "        elif isinstance(use_learnable_lambdas, float):\n",
    "            self.lambdas_raw = nn.Parameter(\n",
    "                torch.ones(1, len(paramslist) - 1) * use_learnable_lambdas,\n",
    "                requires_grad=True,\n",
    "            )  # learnable\n",
    "\n",
    "    def collect_trainable_params(self):\n",
    "        trainable_params = []\n",
    "\n",
    "        # Collect LoRA parameters from backbone blocks\n",
    "        for block in self.mtl_model.backbone.blocks:\n",
    "            if hasattr(block, \"lora\") and block.lora is not None:\n",
    "                trainable_params.append(block.lora.down_proj.weight)\n",
    "                trainable_params.append(block.lora.up_proj.weight)\n",
    "\n",
    "        # Collect LoRA parameters from decoders\n",
    "        for decoder in self.mtl_model.decoders.values():\n",
    "            if hasattr(decoder, \"lora\") and decoder.lora is not None:\n",
    "                trainable_params.append(decoder.lora.down_proj.weight)\n",
    "                trainable_params.append(decoder.lora.up_proj.weight)\n",
    "\n",
    "        if isinstance(self.use_learnable_lambdas, float):\n",
    "            trainable_params.append(self.lambdas_raw)\n",
    "\n",
    "        return trainable_params\n",
    "\n",
    "    def lambdas(self):\n",
    "        pretrain_lambda = torch.ones(\n",
    "            1, 1, device=self.lambdas_raw.device, dtype=self.lambdas_raw.dtype\n",
    "        )\n",
    "        task_lambdas = torch.clamp(self.lambdas_raw, min=0.0, max=1.0)\n",
    "        return torch.cat((pretrain_lambda, task_lambdas), dim=1)\n",
    "\n",
    "    def _merge_parameters(self, _lambda):\n",
    "        \"\"\"Merge parameters based on lambdas.\"\"\"\n",
    "        if _lambda.size(0) == 1:  # task-wise merging\n",
    "            params = tuple(\n",
    "                sum(pi * _lambda_i for pi, _lambda_i in zip(p, _lambda[0].cpu()))\n",
    "                for p in zip(*self.paramslist)\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError(\"Layer-wise merging not implemented with LoRA.\")\n",
    "        return tuple(p.cuda(0) for p in params)\n",
    "\n",
    "    def get_model(self):\n",
    "        _lambda = self.lambdas()\n",
    "        params = self._merge_parameters(_lambda)\n",
    "        load_weights(self.mtl_model, self.names, params)\n",
    "        return self.mtl_model\n",
    "\n",
    "    def forward(self, img, img_metas, return_loss=True, **kwargs):\n",
    "        _lambda = self.lambdas()\n",
    "        params = self._merge_parameters(_lambda)\n",
    "        load_weights(self.mtl_model, self.names, params)\n",
    "        return self.mtl_model(img, img_metas, return_loss=return_loss, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed merging lambda values are used for controlling the contribution of each task vector.\n",
    "rlambda = [[0.4, 0.4, 0.4]]  # Task-specific lambdas for merging\n",
    "simo_model = LambdaWrapper(\n",
    "    pt_model, paramslist, names, rlambda, use_learnable_lambdas=rlambda\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders, metrics, optimizer, and scheduler\n",
    "train_loader, val_loader, test_loader = get_data_loaders(mm_config)\n",
    "train_batch = len(train_loader)\n",
    "\n",
    "mm_config[\"training_params\"][\"total_epochs\"] = 1\n",
    "train_metric = TaskMetric(\n",
    "    train_tasks,\n",
    "    train_tasks,\n",
    "    mm_config[\"training_params\"][\"batch_size\"],\n",
    "    mm_config[\"training_params\"][\"total_epochs\"],\n",
    "    mm_config[\"training_params\"][\"dataset\"],\n",
    "    include_mtl=True,\n",
    ")\n",
    "val_metric = TaskMetric(\n",
    "    train_tasks,\n",
    "    train_tasks,\n",
    "    mm_config[\"training_params\"][\"batch_size\"],\n",
    "    mm_config[\"training_params\"][\"total_epochs\"],\n",
    "    mm_config[\"training_params\"][\"dataset\"],\n",
    "    include_mtl=True,\n",
    ")\n",
    "\n",
    "lr = 1e-5\n",
    "optimizer = optim.AdamW(\n",
    "    simo_model.collect_trainable_params(),\n",
    "    lr=lr,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=0.0,\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=lr,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=mm_config[\"training_params\"][\"total_epochs\"],\n",
    "    pct_start=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop to optimize merging coefficients and LoRA parameters\n",
    "for epoch in range(mm_config[\"training_params\"][\"total_epochs\"]):\n",
    "    train_dataset = iter(train_loader)\n",
    "    for k in range(train_batch):\n",
    "        train_data, train_target = next(train_dataset)\n",
    "        train_data = train_data.to(device)\n",
    "        train_target = {\n",
    "            task_id: train_target[task_id].to(device)\n",
    "            for task_id in simo_model.head_tasks\n",
    "        }\n",
    "\n",
    "        # AdaMerging model\n",
    "        train_res = simo_model(train_data, None, img_gt=train_target, return_loss=True)\n",
    "        optimizer.zero_grad()\n",
    "        train_res[\"total_loss\"].backward()\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            simo_model.collect_trainable_params(), max_norm=35.0, norm_type=2\n",
    "        )\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_metric.update_metric(train_res, train_target)\n",
    "\n",
    "    train_str = train_metric.compute_metric()\n",
    "    wandb.log(\n",
    "        {\n",
    "            **{\n",
    "                f\"train/loss/{task_id}\": train_res[task_id][f\"loss_{task_id}\"]\n",
    "                for task_id in simo_model.head_tasks\n",
    "            },\n",
    "            **{\n",
    "                f\"train/metric/{task_id}\": train_metric.get_metric(task_id)\n",
    "                for task_id in simo_model.head_tasks\n",
    "            },\n",
    "        },\n",
    "    )  # step=epoch\n",
    "    train_metric.reset()\n",
    "\n",
    "    # evaluating\n",
    "    eval_model = simo_model.get_model()\n",
    "    test_str = eval(epoch, eval_model, val_loader, val_metric)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:04d} | TRAIN:{train_str} || TEST:{test_str} | Best: {mm_config['training_params']['task'].title()} {val_metric.get_best_performance(mm_config['training_params']['task']):.4f}\"\n",
    "    )\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"state_dict_lora\": simo_model.mtl_model.backbone.state_dict(),\n",
    "        },\n",
    "        f\"representation_surgery/nyuv2/dinov2/dpt-add_small_head/simo_{epoch}.pt\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the wandb run\n",
    "wandb.finish(quiet=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simo-merging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
