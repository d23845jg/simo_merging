{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Model Merging Notebook\n",
    "\n",
    "This notebook allows to perform traditional model merging techniques on the vision encoder of the MTL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import wandb\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Import Jinja2 for template rendering\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "# Import custom modules for model merging\n",
    "from model_merging.aggregator import aggregate_task_vectors\n",
    "from model_merging.eval_utils import perform_eval_with_merged_vector\n",
    "from model_merging.utils import compute_cosine_similarity_matrix\n",
    "from model_merging.task_vectors import MTLTaskVector\n",
    "\n",
    "from models.dinov2.mtl.multitasker import MTLDinoV2\n",
    "from training.create_network import *\n",
    "from training.utils import TaskMetric, eval\n",
    "\n",
    "from utils import get_data_loaders, initialize_wandb, torch_load, torch_save\n",
    "\n",
    "# Login to Weights & Biases\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Load the configuration template and set up model classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from template\n",
    "env = Environment(loader=FileSystemLoader(\".\"))\n",
    "template = env.get_template(\"config/mtl.yaml.j2\")\n",
    "rendered_yaml = template.render()\n",
    "mm_config = yaml.safe_load(rendered_yaml)\n",
    "\n",
    "# Define model classes\n",
    "model_classes = {\n",
    "    \"dinov2\": MTLDinoV2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wandb Initialization\n",
    "\n",
    "Initialize Weights & Biases for logging experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Weights & Biases for experiment tracking\n",
    "initialize_wandb(\n",
    "    project=mm_config[\"wandb\"][\"project\"],\n",
    "    group=f\"{mm_config['training_params']['network']}\",\n",
    "    job_type=\"model_merging\",\n",
    "    mode=\"offline\",\n",
    "    config={\n",
    "        \"network\": mm_config[\"model_merging\"][\"network\"],\n",
    "        \"dataset\": mm_config[\"model_merging\"][\"dataset\"],\n",
    "        \"batch_size\": mm_config[\"training_params\"][\"batch_size\"],\n",
    "        \"ft_model_files\": mm_config[\"model_merging\"][\"ft_model_files\"],\n",
    "        \"method\": mm_config[\"model_merging\"][\"method\"],\n",
    "        \"seed\": mm_config[\"training_params\"][\"seed\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "Define the tasks and initialize the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tasks = {\n",
    "    \"seg\": {\n",
    "        \"num_classes\": 13,\n",
    "    },  # Semantic segmentation with 13 classes\n",
    "    \"depth\": {\n",
    "        \"num_classes\": 1,\n",
    "        \"min_depth\": 0.00,\n",
    "        \"max_depth\": 10.0,\n",
    "    },  # Depth estimation\n",
    "    \"normal\": {\n",
    "        \"num_classes\": 3,\n",
    "    },  # Surface normal estimation\n",
    "}\n",
    "\n",
    "pt_model = MTLDinoV2(\n",
    "    arch_name=\"vit_base\",\n",
    "    head_tasks=train_tasks,  # Task configurations\n",
    "    head_archs=\"dpt-add_small\",  # Decoder architecture for heads\n",
    "    out_index=[2, 5, 8, 11],  # Output indices from transformer layers\n",
    "    cls_token=True,  # Include class token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Vectors\n",
    "\n",
    "Load fine-tuned models and compute task vectors for each task combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_vectors = {\n",
    "    \" + \".join(task_vector.head_tasks.keys()): task_vector\n",
    "    for ft_file in mm_config[\"model_merging\"][\"ft_model_files\"]\n",
    "    for task_vector in [MTLTaskVector(pt_model, ft_file)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and display the norms of each task vector\n",
    "[task.title() + f\": {task_vectors[task].norm().item():.2f} \" for task in task_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cosine similarity matrix between task vectors\n",
    "compute_cosine_similarity_matrix(task_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "\n",
    "Aggregate the task vectors using the specified merging method to create a multi-task vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate task vectors using the configured merging method (e.g. Task Arithmetic, TIES, ...)\n",
    "mtl_task_vector, masks = aggregate_task_vectors(task_vectors, mm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tasks_str = \" + \".join(task.title() for task in mtl_task_vector.head_tasks.keys())\n",
    "print(\n",
    "    f\"Dataset: {mm_config['model_merging']['dataset'].title()} | Training Task: {train_tasks_str}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluate the performance of the merged model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform evaluation of the merged task vector\n",
    "perform_eval_with_merged_vector(pt_model, mtl_task_vector, mm_config, eval_masks=masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional evaluation at a specific coefficient\n",
    "from model_merging.eval_utils import evaluate_task_vector_at_coef\n",
    "\n",
    "evaluate_task_vector_at_coef(\n",
    "    pt_model, mtl_task_vector, mm_config, 0.4, use_val_dataset=False, eval_masks=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Finish the Weights & Biases run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the Weights & Biases run quietly\n",
    "wandb.finish(quiet=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simo-merging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
