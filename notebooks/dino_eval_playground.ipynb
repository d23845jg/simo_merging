{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMO Evaluation Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for PyTorch, optimization, file handling, and configuration\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import yaml\n",
    "import wandb\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "# Import custom modules for dataset creation, network setup, MTL, training utils, and general utils\n",
    "from training.create_dataset import *\n",
    "from training.create_network import *\n",
    "from models.dinov2.mtl.multitasker import MTLDinoV2\n",
    "from training.utils import create_task_flags, TaskMetric, eval\n",
    "from utils import torch_load, torch_save, get_data_loaders, initialize_wandb\n",
    "\n",
    "# Login to wandb for experiment tracking\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Loading the experiment configuration from a Jinja2 template file. This includes hyperparameters for training, model merging settings, and dataset configurations. The configuration is rendered and parsed as YAML for easy access throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and render the configuration template\n",
    "env = Environment(loader=FileSystemLoader(\".\"))\n",
    "template = env.get_template(\"config/mtl.yaml.j2\")\n",
    "rendered_yaml = template.render()\n",
    "config = yaml.safe_load(rendered_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Weights & Biases for logging\n",
    "initialize_wandb(\n",
    "    project=config[\"wandb\"][\"project\"],\n",
    "    group=f\"{config['training_params']['network']}\",\n",
    "    job_type=\"task_specific\",\n",
    "    mode=\"offline\",\n",
    "    config={\n",
    "        \"task\": config[\"training_params\"][\"task\"],\n",
    "        \"network\": config[\"training_params\"][\"network\"],\n",
    "        \"dataset\": config[\"training_params\"][\"dataset\"],\n",
    "        \"epochs\": config[\"training_params\"][\"total_epochs\"],\n",
    "        \"batch_size\": config[\"training_params\"][\"batch_size\"],\n",
    "        \"seed\": config[\"training_params\"][\"seed\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(config[\"training_params\"][\"seed\"])\n",
    "np.random.seed(config[\"training_params\"][\"seed\"])\n",
    "random.seed(config[\"training_params\"][\"seed\"])\n",
    "\n",
    "# Determine the device for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading and Evaluation\n",
    "\n",
    "Define the tasks for evaluation, load the data loaders, initialize the evaluation metric, load the pre-trained model, and perform evaluation on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tasks for evaluation with their parameters\n",
    "train_tasks = {\n",
    "  \"seg\": {\"num_classes\": 13,},\n",
    "  \"depth\": {\"num_classes\": 1, \"min_depth\": 0.00, \"max_depth\": 10.0,},\n",
    "  \"normal\": {\"num_classes\": 3,}\n",
    "}\n",
    "\n",
    "# Load data loaders for training, validation, and testing\n",
    "train_loader, val_loader, test_loader = get_data_loaders(config)\n",
    "\n",
    "# Initialize the evaluation metric\n",
    "test_metric = TaskMetric(\n",
    "    train_tasks,\n",
    "    train_tasks,\n",
    "    config[\"training_params\"][\"batch_size\"],\n",
    "    1,\n",
    "    config[\"training_params\"][\"dataset\"],\n",
    ")\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = torch_load(\n",
    "    \"checkpoints/nyuv2/dinov2/dpt-add_small_head/mtl/final/simo_model.pt\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Perform evaluation on the test set\n",
    "eval(1, model, test_loader, test_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
